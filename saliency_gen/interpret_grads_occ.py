"""
This script generates and serializes saliency maps using various attribution methods, including gradient-based approaches (Saliency, Guided Backprop, DeepLift, etc.) and Occlusion. The results are saved to disk for further analysis.

Modules:
- argparse: For parsing command-line arguments.
- json: For serializing results into JSON format.
- os: For file operations.
- random: For random number generation with a fixed seed.
- torch: For deep learning operations and model management.
- captum.attr: For various saliency attribution methods.
- tqdm: For displaying progress bars.
- transformers: For working with pre-trained BERT models.
- models.data_loader: For loading the dataset.
- models.model_builder: For building the CNN model.

Functions:
- summarize_attributions: Summarizes saliency attribution maps generated by saliency methods.
- BertModelWrapper: A wrapper for BERT-based models to extract embeddings.
- get_model_embedding_emb: Retrieves the embedding layer of the model.
- generate_saliency: Generates saliency maps and saves them to disk.
"""

import argparse
import json
import os
import random
from argparse import Namespace
from collections import defaultdict
from functools import partial

import numpy as np
import torch
from captum.attr import DeepLift, GuidedBackprop, InputXGradient, Occlusion, \
    Saliency, configure_interpretable_embedding_layer, \
    remove_interpretable_embedding_layer
from torch.utils.data import DataLoader
from tqdm import tqdm
from transformers import BertTokenizer

from models.data_loader import collate_nli, NLIDataset
from models.model_builder import CNN_MODEL
import time

def summarize_attributions(attributions, type='mean', model=None, tokens=None):
    """
    Summarizes saliency attributions according to the specified method.

    Args:
        attributions (torch.Tensor): Attribution values to summarize.
        type (str): The type of summarization ('none', 'dot', 'mean', 'l2').
        model (torch.nn.Module): The model used to get embeddings (optional).
        tokens (list): The tokenized input (optional).

    Returns:
        torch.Tensor: The summarized attribution values.
    """
    if type == 'none':
        return attributions
    elif type == 'dot':
        embeddings = get_model_embedding_emb(model)(tokens)
        attributions = torch.einsum('bwd, bwd->bw', attributions, embeddings)
    elif type == 'mean':
        attributions = attributions.mean(dim=-1).squeeze(0)
        attributions = attributions / torch.norm(attributions)
    elif type == 'l2':
        attributions = attributions.norm(p=1, dim=-1).squeeze(0)
    return attributions

class BertModelWrapper(torch.nn.Module):
    """
    A wrapper class for BERT-based models to extract embeddings.

    Args:
        model (transformers.BertModel): The pre-trained BERT model.

    Methods:
        forward(input, attention_mask, labels): Passes input through the model and returns embeddings.
    """
    def __init__(self, model):
        super(BertModelWrapper, self).__init__()
        self.model = model

    def forward(self, input, attention_mask, labels):
        return self.model(input, attention_mask=attention_mask)[0]

def get_model_embedding_emb(model):
    """
    Retrieves the embedding layer from the model.

    Args:
        model (torch.nn.Module): The model from which to extract the embedding layer.

    Returns:
        torch.nn.Module: The embedding layer of the model.
    """
    return model.embedding.embedding

def generate_saliency(model_path, saliency_path, saliency, aggregation):
    """
    Generates saliency maps using a specified attribution method and saves them to disk.

    Args:
        model_path (str): Path to the trained model checkpoint.
        saliency_path (str): Path where the saliency maps will be saved.
        saliency (str): The saliency attribution method ('deeplift', 'guided', 'sal', 'inputx', 'occlusion').
        aggregation (str): The aggregation method for saliency ('mean', 'l2', 'none').

    Returns:
        list: List of FLOPS (floating point operations) for each batch.
    """
    checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)
    model_args = checkpoint['args']
    
    model = CNN_MODEL(tokenizer, model_args, n_labels=checkpoint['args']['labels']).to(device)
    model.load_state_dict(checkpoint['model'])
    model.train()
    
    pad_to_max = False
    
    # Select saliency method
    if saliency == 'deeplift':
        ablator = DeepLift(model)
    elif saliency == 'guided':
        ablator = GuidedBackprop(model)
    elif saliency == 'sal':
        ablator = Saliency(model)
    elif saliency == 'inputx':
        ablator = InputXGradient(model)
    elif saliency == 'occlusion':
        ablator = Occlusion(model)

    collate_fn = partial(collate_nli, tokenizer=tokenizer, device=device,
                         return_attention_masks=False, pad_to_max_length=pad_to_max)
    test = NLIDataset(args["dataset_dir"], type=args["split"], salient_features=True)
    batch_size = args["batch_size"] if args["batch_size"] is not None else model_args['batch_size']
    test_dl = DataLoader(batch_size=batch_size, dataset=test, shuffle=False, collate_fn=collate_fn)

    predictions_path = model_path + '.predictions'
    if not os.path.exists(predictions_path):
        predictions = defaultdict(lambda: [])
        for batch in tqdm(test_dl, desc='Running test prediction... '):
            logits = model(batch[0])
            logits = logits.detach().cpu().numpy().tolist()
            predicted = np.argmax(np.array(logits), axis=-1)
            predictions['class'] += predicted.tolist()
            predictions['logits'] += logits

        with open(predictions_path, 'w') as out:
            json.dump(predictions, out)

    if saliency != 'occlusion':
        embedding_layer_name = 'embedding'
        interpretable_embedding = configure_interpretable_embedding_layer(model, embedding_layer_name)

    class_attr_list = defaultdict(lambda: [])
    token_ids = []
    saliency_flops = []

    for batch in tqdm(test_dl, desc='Running Saliency Generation...'):
        additional = None
        token_ids += batch[0].detach().cpu().numpy().tolist()
        if saliency != 'occlusion':
            input_embeddings = interpretable_embedding.indices_to_embeddings(batch[0])

        start = time.time()

        for cls_ in range(checkpoint['args']['labels']):
            if saliency == 'occlusion':
                attributions = ablator.attribute(batch[0], sliding_window_shapes=(args["sw"],), target=cls_, additional_forward_args=additional)
            else:
                attributions = ablator.attribute(input_embeddings, target=cls_, additional_forward_args=additional)

            attributions = summarize_attributions(attributions, type=aggregation, model=model, tokens=batch[0]).detach().cpu().numpy().tolist()
            class_attr_list[cls_] += [[_li for _li in _l] for _l in attributions]

        end = time.time()
        saliency_flops.append((end - start) / batch[0].shape[0])

    if saliency != 'occlusion':
        remove_interpretable_embedding_layer(model, interpretable_embedding)

    print('Serializing...', flush=True)
    with open(saliency_path, 'w') as out:
        for instance_i, _ in enumerate(test):
            saliencies = []
            for token_i, token_id in enumerate(token_ids[instance_i]):
                token_sal = {'token': tokenizer.ids_to_tokens[token_id]}
                for cls_ in range(checkpoint['args']['labels']):
                    token_sal[int(cls_)] = class_attr_list[cls_][instance_i][token_i]
                saliencies.append(token_sal)

            out.write(json.dumps({'tokens': saliencies}) + '\n')
            out.flush()

    return saliency_flops

args = {
    "dataset": "snli",  
    "dataset_dir": "data/e-SNLI/dataset/",  
    "split": "test",  
    "model": "cnn",  
    "models_dir": ["data/models/snli/cnn/cnn", "data/models/snli/random_cnn/cnn"],  
    "gpu": False,  
    "seed": 73,  
    "output_dir": ["data/saliency/snli/cnn/", "data/saliency/snli/random_cnn/"],  
    "sw": 1,  
    "saliency": ["guided", "sal", "inputx", "occlusion"],  
    "batch_size": None  
}

random.seed(args["seed"])
torch.manual_seed(args["seed"])
torch.cuda.manual_seed_all(args["seed"])
torch.backends.cudnn.deterministic = True
np.random.seed(args["seed"])

device = torch.device("cuda") if args["gpu"] else torch.device("cpu")
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

for saliency in args["saliency"]:
    print('Running Saliency ', saliency, flush=True)

    if saliency in ['guided', 'sal', 'inputx', 'deeplift']:
        aggregations = ['mean', 'l2']
    else:
        aggregations = ['none']

    for aggregation in aggregations:
        flops = []
        print('Running aggregation ', aggregation, flush=True)

        for models_dir, output_dir in zip(args["models_dir"], args["output_dir"]):
            base_model_name = models_dir.split('/')[-1]
            for model in range(1, 6):
                curr_flops = generate_saliency(
                    os.path.join(models_dir + f'_{model}'),
                    os.path.join(output_dir, f'{base_model_name}_{model}_{saliency}_{aggregation}'),
                    saliency,
                    aggregation)

                flops.append(np.average(curr_flops))

            print('FLOPS', np.average(flops), np.std(flops), flush=True)
            print()
            print()

